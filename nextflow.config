params
{
    /*
     * Set up.
     */

    INPUTS_CSV = "${launchDir}/alignment.csv"

    FASTQ_DIR = "${launchDir}/fastq"

    ALIGNED_DIR = "${launchDir}/processed"

    REPORTS_DIR = "${launchDir}/reports"

    /*
     * Reference files.
     */

    ASSEMBLY = "hg38"

    REFERENCE_ROOT = "/mnt/scratcha/bioinformatics/rosenfeld_references"

    REFERENCE_FASTA = "${REFERENCE_ROOT}/${ASSEMBLY}/fasta/${ASSEMBLY}.fa"
    BWAMEM2_INDEX = "${REFERENCE_ROOT}/${ASSEMBLY}/bwamem2-2.2.1/${ASSEMBLY}"

    /*
     * Trimming.
     */

    // Whether to trim or not.
    TRIM_FASTQ = false

    // Permitted range for read lengths as a fraction of the original read length. (Min: 0 and Max: 100).
    TRIM_MINIMUM_FRACTION_READ = 10

    // Quality Threshold for Trimming (Min: 0 and Max: 50).
    TRIM_QUALITY_THRESHOLD = 5

    /*
     * Alignment.
     */

    MARK_DUPLICATES = true

    // The number of reads in each chunk for alignment
    CHUNK_SIZE = 10000000

    /*
     * GATK base quality score recalibration
     */

    GATK_BQSR = false

    GATK_KNOWN_SITES = "${REFERENCE_ROOT}/${ASSEMBLY}/dbsnp/${ASSEMBLY}.snps.vcf.gz"

    /*
     * QC
     */

    FASTQC = false

    /*
     * Id extraction from the driver CSV file.
     */

    // A list of the column headers that make up the unit id for the pipeline.
    // These are used in order.
    UNIT_ID_PARTS = [ 'SLXId', 'Barcode', 'Flowcell', 'Lane' ]

    // The character or string to put between the unit id values.
    UNIT_ID_SEPARATOR = '.'

    // A list of the column headers that make up the sample id for the pipeline.
    // These are used in order.
    SAMPLE_ID_PARTS = [ 'SLXId', 'Barcode' ]

    // The character or string to put between the sample id values.
    SAMPLE_ID_SEPARATOR = '.'
}



manifest
{
    mainScript = 'tap.nf'
    nextflowVersion = '>=20.0.0'
    version = '2.0.0'
    recurseSubmodules = true
    author = 'Richard Bowers, Matthew Eldridge'
    homePage = 'https://github.com/nrlab-CRUK/TAP'
    name = 'Rosenfeld Trim and Align Pipeline'
    description = """
        Sequence data trimming and alignment pipeline.
    """
}

executor
{
    $slurm
    {
        queueSize = 150
        pollInterval = '30sec'
        queue = 'general'
        clusterOptions = "--nodes=1 --open-mode=truncate"
    }
}

singularity.enabled = true
singularity.autoMounts = true
singularity.runOptions = "-B '${projectDir}'"

process
{
    // container = 'nrlabcruk/nrlabtap'
    container = "/home/bioinformatics/pipelinesoftware/nrlab_tap/nrlabtap-latest.sif"

    errorStrategy =
    {
        task.exitStatus in [143,137,104,134,139,140] ? 'retry' : 'finish'
    }

    cpus = 1
    memory = 1.GB
    time = 1.hour

    withLabel:picard
    {
       memory = { 4.GB * 2 ** (task.attempt - 1) } // So 4, 8, 16 etc
       time = { 4.hour * task.attempt }
       maxRetries = 2
    }

    withLabel:gatk
    {
       memory = { 4.GB * 2 ** (task.attempt - 1) } // So 4, 8, 16 etc
       time = { 4.hour * task.attempt }
       maxRetries = 2
    }
}

profiles
{
    standard
    {
        // The default is, on request, the same as the "slurm" profile.
        process.executor = 'slurm'
        executor
        {
            queueSize = 100
            pollInterval = 30.sec
            jobName = { "'$task.name'" }
        }
    }

    slurm
    {
        process.executor = 'slurm'
        executor
        {
            queueSize = 100
            pollInterval = 30.sec
            jobName = { "'$task.name'" }
        }
    }

    bigserver
    {
        process.executor = 'local'
        executor
        {
            cpus = 28
            memory = 180.GB
        }
    }
}

env
{
    TAP_HOME = projectDir
}

timeline
{
    enabled = false
    file = "${launchDir}/work/execution_timeline.html"
}
report
{
    enabled = false
    file = "${launchDir}/work/execution_report.html"
}
